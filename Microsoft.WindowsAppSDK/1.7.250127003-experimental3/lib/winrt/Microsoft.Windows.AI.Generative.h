// WARNING: Please don't edit this file. It was generated by C++/WinRT v2.0.240405.15

#pragma once
#ifndef WINRT_Microsoft_Windows_AI_Generative_H
#define WINRT_Microsoft_Windows_AI_Generative_H
#include "winrt/base.h"
static_assert(winrt::check_version(CPPWINRT_VERSION, "2.0.240405.15"), "Mismatched C++/WinRT headers.");
#define CPPWINRT_VERSION "2.0.240405.15"
#include "winrt/impl/Microsoft.Graphics.Imaging.2.h"
#include "winrt/impl/Microsoft.Windows.AI.ContentModeration.2.h"
#include "winrt/impl/Microsoft.Windows.Management.Deployment.2.h"
#include "winrt/impl/Microsoft.Windows.SemanticSearch.2.h"
#include "winrt/impl/Windows.Foundation.2.h"
#include "winrt/impl/Windows.Foundation.Collections.2.h"
#include "winrt/impl/Microsoft.Windows.AI.Generative.2.h"
namespace winrt::impl
{
    template <typename D> auto consume_Microsoft_Windows_AI_Generative_IImageDescriptionGenerator<D>::DescribeAsync(winrt::Microsoft::Graphics::Imaging::ImageBuffer const& image) const
    {
        void* operation{};
        check_hresult(WINRT_IMPL_SHIM(winrt::Microsoft::Windows::AI::Generative::IImageDescriptionGenerator)->DescribeAsync(*(void**)(&image), &operation));
        return winrt::Windows::Foundation::IAsyncOperationWithProgress<winrt::Microsoft::Windows::AI::Generative::LanguageModelResponse, hstring>{ operation, take_ownership_from_abi };
    }
    template <typename D> auto consume_Microsoft_Windows_AI_Generative_IImageDescriptionGenerator2<D>::DescribeAsync(winrt::Microsoft::Graphics::Imaging::ImageBuffer const& image, winrt::Microsoft::Windows::AI::Generative::ImageDescriptionScenario const& scenario) const
    {
        void* operation{};
        check_hresult(WINRT_IMPL_SHIM(winrt::Microsoft::Windows::AI::Generative::IImageDescriptionGenerator2)->DescribeAsync(*(void**)(&image), static_cast<int32_t>(scenario), &operation));
        return winrt::Windows::Foundation::IAsyncOperationWithProgress<winrt::Microsoft::Windows::AI::Generative::LanguageModelResponse, hstring>{ operation, take_ownership_from_abi };
    }
    template <typename D> auto consume_Microsoft_Windows_AI_Generative_IImageDescriptionGenerator3<D>::DescribeAsync(winrt::Microsoft::Graphics::Imaging::ImageBuffer const& image, winrt::Microsoft::Windows::AI::Generative::ImageDescriptionScenario const& scenario, winrt::Microsoft::Windows::AI::ContentModeration::ContentFilterOptions const& contentFilterOptions) const
    {
        void* operation{};
        check_hresult(WINRT_IMPL_SHIM(winrt::Microsoft::Windows::AI::Generative::IImageDescriptionGenerator3)->DescribeAsync(*(void**)(&image), static_cast<int32_t>(scenario), *(void**)(&contentFilterOptions), &operation));
        return winrt::Windows::Foundation::IAsyncOperationWithProgress<winrt::Microsoft::Windows::AI::Generative::LanguageModelResponse, hstring>{ operation, take_ownership_from_abi };
    }
    template <typename D> auto consume_Microsoft_Windows_AI_Generative_IImageDescriptionGeneratorStatics<D>::IsAvailable() const
    {
        bool result{};
        check_hresult(WINRT_IMPL_SHIM(winrt::Microsoft::Windows::AI::Generative::IImageDescriptionGeneratorStatics)->IsAvailable(&result));
        return result;
    }
    template <typename D> auto consume_Microsoft_Windows_AI_Generative_IImageDescriptionGeneratorStatics<D>::MakeAvailableAsync() const
    {
        void* operation{};
        check_hresult(WINRT_IMPL_SHIM(winrt::Microsoft::Windows::AI::Generative::IImageDescriptionGeneratorStatics)->MakeAvailableAsync(&operation));
        return winrt::Windows::Foundation::IAsyncOperationWithProgress<winrt::Microsoft::Windows::Management::Deployment::PackageDeploymentResult, winrt::Microsoft::Windows::Management::Deployment::PackageDeploymentProgress>{ operation, take_ownership_from_abi };
    }
    template <typename D> auto consume_Microsoft_Windows_AI_Generative_IImageDescriptionGeneratorStatics<D>::CreateAsync() const
    {
        void* operation{};
        check_hresult(WINRT_IMPL_SHIM(winrt::Microsoft::Windows::AI::Generative::IImageDescriptionGeneratorStatics)->CreateAsync(&operation));
        return winrt::Windows::Foundation::IAsyncOperation<winrt::Microsoft::Windows::AI::Generative::ImageDescriptionGenerator>{ operation, take_ownership_from_abi };
    }
    template <typename D> auto consume_Microsoft_Windows_AI_Generative_ILanguageModel<D>::GenerateResponseAsync(param::hstring const& prompt) const
    {
        void* operation{};
        check_hresult(WINRT_IMPL_SHIM(winrt::Microsoft::Windows::AI::Generative::ILanguageModel)->GenerateResponseAsync(*(void**)(&prompt), &operation));
        return winrt::Windows::Foundation::IAsyncOperation<winrt::Microsoft::Windows::AI::Generative::LanguageModelResponse>{ operation, take_ownership_from_abi };
    }
    template <typename D> auto consume_Microsoft_Windows_AI_Generative_ILanguageModel<D>::GenerateResponseWithProgressAsync(param::hstring const& prompt) const
    {
        void* operation{};
        check_hresult(WINRT_IMPL_SHIM(winrt::Microsoft::Windows::AI::Generative::ILanguageModel)->GenerateResponseWithProgressAsync(*(void**)(&prompt), &operation));
        return winrt::Windows::Foundation::IAsyncOperationWithProgress<winrt::Microsoft::Windows::AI::Generative::LanguageModelResponse, hstring>{ operation, take_ownership_from_abi };
    }
    template <typename D> auto consume_Microsoft_Windows_AI_Generative_ILanguageModel2<D>::GenerateResponseFromEmbeddingsWithProgressAsync(param::async_vector_view<winrt::Microsoft::Windows::SemanticSearch::EmbeddingVector> const& promptEmbedding) const
    {
        void* operation{};
        check_hresult(WINRT_IMPL_SHIM(winrt::Microsoft::Windows::AI::Generative::ILanguageModel2)->GenerateResponseFromEmbeddingsWithProgressAsync(*(void**)(&promptEmbedding), &operation));
        return winrt::Windows::Foundation::IAsyncOperationWithProgress<winrt::Microsoft::Windows::AI::Generative::LanguageModelResponse, hstring>{ operation, take_ownership_from_abi };
    }
    template <typename D> auto consume_Microsoft_Windows_AI_Generative_ILanguageModel2<D>::GenerateEmbeddingVector(param::hstring const& prompt) const
    {
        void* result{};
        check_hresult(WINRT_IMPL_SHIM(winrt::Microsoft::Windows::AI::Generative::ILanguageModel2)->GenerateEmbeddingVector(*(void**)(&prompt), &result));
        return winrt::Windows::Foundation::Collections::IVectorView<winrt::Microsoft::Windows::SemanticSearch::EmbeddingVector>{ result, take_ownership_from_abi };
    }
    template <typename D> auto consume_Microsoft_Windows_AI_Generative_ILanguageModel2<D>::GenerateEmbeddingVectorAsync(param::hstring const& prompt) const
    {
        void* operation{};
        check_hresult(WINRT_IMPL_SHIM(winrt::Microsoft::Windows::AI::Generative::ILanguageModel2)->GenerateEmbeddingVectorAsync(*(void**)(&prompt), &operation));
        return winrt::Windows::Foundation::IAsyncOperation<winrt::Windows::Foundation::Collections::IVectorView<winrt::Microsoft::Windows::SemanticSearch::EmbeddingVector>>{ operation, take_ownership_from_abi };
    }
    template <typename D> auto consume_Microsoft_Windows_AI_Generative_ILanguageModel2<D>::IsPromptLargerThanContext(param::hstring const& prompt) const
    {
        bool result{};
        check_hresult(WINRT_IMPL_SHIM(winrt::Microsoft::Windows::AI::Generative::ILanguageModel2)->IsPromptLargerThanContext(*(void**)(&prompt), &result));
        return result;
    }
    template <typename D> auto consume_Microsoft_Windows_AI_Generative_ILanguageModel3<D>::GenerateResponseAsync(winrt::Microsoft::Windows::AI::Generative::LanguageModelOptions const& options, param::hstring const& prompt) const
    {
        void* operation{};
        check_hresult(WINRT_IMPL_SHIM(winrt::Microsoft::Windows::AI::Generative::ILanguageModel3)->GenerateResponseAsync(*(void**)(&options), *(void**)(&prompt), &operation));
        return winrt::Windows::Foundation::IAsyncOperation<winrt::Microsoft::Windows::AI::Generative::LanguageModelResponse>{ operation, take_ownership_from_abi };
    }
    template <typename D> auto consume_Microsoft_Windows_AI_Generative_ILanguageModel3<D>::GenerateResponseFromEmbeddingsWithProgressAsync(winrt::Microsoft::Windows::AI::Generative::LanguageModelOptions const& options, param::async_vector_view<winrt::Microsoft::Windows::SemanticSearch::EmbeddingVector> const& promptEmbedding) const
    {
        void* operation{};
        check_hresult(WINRT_IMPL_SHIM(winrt::Microsoft::Windows::AI::Generative::ILanguageModel3)->GenerateResponseFromEmbeddingsWithProgressAsync(*(void**)(&options), *(void**)(&promptEmbedding), &operation));
        return winrt::Windows::Foundation::IAsyncOperationWithProgress<winrt::Microsoft::Windows::AI::Generative::LanguageModelResponse, hstring>{ operation, take_ownership_from_abi };
    }
    template <typename D> auto consume_Microsoft_Windows_AI_Generative_ILanguageModel4<D>::GenerateResponseWithProgressAsync(winrt::Microsoft::Windows::AI::Generative::LanguageModelOptions const& options, param::hstring const& prompt) const
    {
        void* operation{};
        check_hresult(WINRT_IMPL_SHIM(winrt::Microsoft::Windows::AI::Generative::ILanguageModel4)->GenerateResponseWithProgressAsync(*(void**)(&options), *(void**)(&prompt), &operation));
        return winrt::Windows::Foundation::IAsyncOperationWithProgress<winrt::Microsoft::Windows::AI::Generative::LanguageModelResponse, hstring>{ operation, take_ownership_from_abi };
    }
    template <typename D> auto consume_Microsoft_Windows_AI_Generative_ILanguageModel4<D>::GenerateTokens(param::hstring const& text) const
    {
        void* result{};
        check_hresult(WINRT_IMPL_SHIM(winrt::Microsoft::Windows::AI::Generative::ILanguageModel4)->GenerateTokens(*(void**)(&text), &result));
        return winrt::Windows::Foundation::Collections::IVectorView<int64_t>{ result, take_ownership_from_abi };
    }
    template <typename D> auto consume_Microsoft_Windows_AI_Generative_ILanguageModel4<D>::GenerateTokensAsync(param::hstring const& text) const
    {
        void* operation{};
        check_hresult(WINRT_IMPL_SHIM(winrt::Microsoft::Windows::AI::Generative::ILanguageModel4)->GenerateTokensAsync(*(void**)(&text), &operation));
        return winrt::Windows::Foundation::IAsyncOperation<winrt::Windows::Foundation::Collections::IVectorView<int64_t>>{ operation, take_ownership_from_abi };
    }
    template <typename D> auto consume_Microsoft_Windows_AI_Generative_ILanguageModel4<D>::GenerateResponseFromTokensWithProgressAsync(winrt::Microsoft::Windows::AI::Generative::LanguageModelOptions const& options, param::async_vector_view<int64_t> const& promptTokens) const
    {
        void* operation{};
        check_hresult(WINRT_IMPL_SHIM(winrt::Microsoft::Windows::AI::Generative::ILanguageModel4)->GenerateResponseFromTokensWithProgressAsync(*(void**)(&options), *(void**)(&promptTokens), &operation));
        return winrt::Windows::Foundation::IAsyncOperationWithProgress<winrt::Microsoft::Windows::AI::Generative::LanguageModelResponse, hstring>{ operation, take_ownership_from_abi };
    }
    template <typename D> auto consume_Microsoft_Windows_AI_Generative_ILanguageModel5<D>::GenerateResponseAsync(winrt::Microsoft::Windows::AI::Generative::LanguageModelOptions const& options, param::hstring const& prompt, winrt::Microsoft::Windows::AI::ContentModeration::ContentFilterOptions const& contentFilterOptions) const
    {
        void* operation{};
        check_hresult(WINRT_IMPL_SHIM(winrt::Microsoft::Windows::AI::Generative::ILanguageModel5)->GenerateResponseAsync(*(void**)(&options), *(void**)(&prompt), *(void**)(&contentFilterOptions), &operation));
        return winrt::Windows::Foundation::IAsyncOperation<winrt::Microsoft::Windows::AI::Generative::LanguageModelResponse>{ operation, take_ownership_from_abi };
    }
    template <typename D> auto consume_Microsoft_Windows_AI_Generative_ILanguageModel5<D>::GenerateResponseWithProgressAsync(winrt::Microsoft::Windows::AI::Generative::LanguageModelOptions const& options, param::hstring const& prompt, winrt::Microsoft::Windows::AI::ContentModeration::ContentFilterOptions const& contentFilterOptions) const
    {
        void* operation{};
        check_hresult(WINRT_IMPL_SHIM(winrt::Microsoft::Windows::AI::Generative::ILanguageModel5)->GenerateResponseWithProgressAsync(*(void**)(&options), *(void**)(&prompt), *(void**)(&contentFilterOptions), &operation));
        return winrt::Windows::Foundation::IAsyncOperationWithProgress<winrt::Microsoft::Windows::AI::Generative::LanguageModelResponse, hstring>{ operation, take_ownership_from_abi };
    }
    template <typename D> auto consume_Microsoft_Windows_AI_Generative_ILanguageModel5<D>::GenerateResponseFromEmbeddingsWithProgressAsync(winrt::Microsoft::Windows::AI::Generative::LanguageModelOptions const& options, param::async_vector_view<winrt::Microsoft::Windows::SemanticSearch::EmbeddingVector> const& promptEmbedding, winrt::Microsoft::Windows::AI::ContentModeration::ContentFilterOptions const& contentFilterOptions) const
    {
        void* operation{};
        check_hresult(WINRT_IMPL_SHIM(winrt::Microsoft::Windows::AI::Generative::ILanguageModel5)->GenerateResponseFromEmbeddingsWithProgressAsync(*(void**)(&options), *(void**)(&promptEmbedding), *(void**)(&contentFilterOptions), &operation));
        return winrt::Windows::Foundation::IAsyncOperationWithProgress<winrt::Microsoft::Windows::AI::Generative::LanguageModelResponse, hstring>{ operation, take_ownership_from_abi };
    }
    template <typename D> auto consume_Microsoft_Windows_AI_Generative_ILanguageModel5<D>::GenerateResponseFromTokensWithProgressAsync(winrt::Microsoft::Windows::AI::Generative::LanguageModelOptions const& options, param::async_vector_view<int64_t> const& promptTokens, winrt::Microsoft::Windows::AI::ContentModeration::ContentFilterOptions const& contentFilterOptions) const
    {
        void* operation{};
        check_hresult(WINRT_IMPL_SHIM(winrt::Microsoft::Windows::AI::Generative::ILanguageModel5)->GenerateResponseFromTokensWithProgressAsync(*(void**)(&options), *(void**)(&promptTokens), *(void**)(&contentFilterOptions), &operation));
        return winrt::Windows::Foundation::IAsyncOperationWithProgress<winrt::Microsoft::Windows::AI::Generative::LanguageModelResponse, hstring>{ operation, take_ownership_from_abi };
    }
    template <typename D> auto consume_Microsoft_Windows_AI_Generative_ILanguageModel5<D>::GenerateResponseAsync(winrt::Microsoft::Windows::AI::Generative::LanguageModelOptions const& options, param::hstring const& prompt, winrt::Microsoft::Windows::AI::ContentModeration::ContentFilterOptions const& contentFilterOptions, winrt::Microsoft::Windows::AI::Generative::LanguageModelContext const& context) const
    {
        void* operation{};
        check_hresult(WINRT_IMPL_SHIM(winrt::Microsoft::Windows::AI::Generative::ILanguageModel5)->GenerateResponseAsync2(*(void**)(&options), *(void**)(&prompt), *(void**)(&contentFilterOptions), *(void**)(&context), &operation));
        return winrt::Windows::Foundation::IAsyncOperation<winrt::Microsoft::Windows::AI::Generative::LanguageModelResponse>{ operation, take_ownership_from_abi };
    }
    template <typename D> auto consume_Microsoft_Windows_AI_Generative_ILanguageModel5<D>::GenerateResponseWithProgressAsync(winrt::Microsoft::Windows::AI::Generative::LanguageModelOptions const& options, param::hstring const& prompt, winrt::Microsoft::Windows::AI::ContentModeration::ContentFilterOptions const& contentFilterOptions, winrt::Microsoft::Windows::AI::Generative::LanguageModelContext const& context) const
    {
        void* operation{};
        check_hresult(WINRT_IMPL_SHIM(winrt::Microsoft::Windows::AI::Generative::ILanguageModel5)->GenerateResponseWithProgressAsync2(*(void**)(&options), *(void**)(&prompt), *(void**)(&contentFilterOptions), *(void**)(&context), &operation));
        return winrt::Windows::Foundation::IAsyncOperationWithProgress<winrt::Microsoft::Windows::AI::Generative::LanguageModelResponse, hstring>{ operation, take_ownership_from_abi };
    }
    template <typename D> auto consume_Microsoft_Windows_AI_Generative_ILanguageModel5<D>::GenerateResponseFromEmbeddingsWithProgressAsync(winrt::Microsoft::Windows::AI::Generative::LanguageModelOptions const& options, param::async_vector_view<winrt::Microsoft::Windows::SemanticSearch::EmbeddingVector> const& promptEmbedding, winrt::Microsoft::Windows::AI::ContentModeration::ContentFilterOptions const& contentFilterOptions, winrt::Microsoft::Windows::AI::Generative::LanguageModelContext const& context) const
    {
        void* operation{};
        check_hresult(WINRT_IMPL_SHIM(winrt::Microsoft::Windows::AI::Generative::ILanguageModel5)->GenerateResponseFromEmbeddingsWithProgressAsync2(*(void**)(&options), *(void**)(&promptEmbedding), *(void**)(&contentFilterOptions), *(void**)(&context), &operation));
        return winrt::Windows::Foundation::IAsyncOperationWithProgress<winrt::Microsoft::Windows::AI::Generative::LanguageModelResponse, hstring>{ operation, take_ownership_from_abi };
    }
    template <typename D> auto consume_Microsoft_Windows_AI_Generative_ILanguageModel5<D>::GenerateResponseFromTokensWithProgressAsync(winrt::Microsoft::Windows::AI::Generative::LanguageModelOptions const& options, param::async_vector_view<int64_t> const& promptTokens, winrt::Microsoft::Windows::AI::ContentModeration::ContentFilterOptions const& contentFilterOptions, winrt::Microsoft::Windows::AI::Generative::LanguageModelContext const& context) const
    {
        void* operation{};
        check_hresult(WINRT_IMPL_SHIM(winrt::Microsoft::Windows::AI::Generative::ILanguageModel5)->GenerateResponseFromTokensWithProgressAsync2(*(void**)(&options), *(void**)(&promptTokens), *(void**)(&contentFilterOptions), *(void**)(&context), &operation));
        return winrt::Windows::Foundation::IAsyncOperationWithProgress<winrt::Microsoft::Windows::AI::Generative::LanguageModelResponse, hstring>{ operation, take_ownership_from_abi };
    }
    template <typename D> auto consume_Microsoft_Windows_AI_Generative_ILanguageModel5<D>::GenerateEmbeddingVector(param::hstring const& prompt, winrt::Microsoft::Windows::AI::ContentModeration::ContentFilterOptions const& contentFilterOptions) const
    {
        void* result{};
        check_hresult(WINRT_IMPL_SHIM(winrt::Microsoft::Windows::AI::Generative::ILanguageModel5)->GenerateEmbeddingVector(*(void**)(&prompt), *(void**)(&contentFilterOptions), &result));
        return winrt::Windows::Foundation::Collections::IVectorView<winrt::Microsoft::Windows::SemanticSearch::EmbeddingVector>{ result, take_ownership_from_abi };
    }
    template <typename D> auto consume_Microsoft_Windows_AI_Generative_ILanguageModel5<D>::GenerateEmbeddingVectorAsync(param::hstring const& prompt, winrt::Microsoft::Windows::AI::ContentModeration::ContentFilterOptions const& contentFilterOptions) const
    {
        void* operation{};
        check_hresult(WINRT_IMPL_SHIM(winrt::Microsoft::Windows::AI::Generative::ILanguageModel5)->GenerateEmbeddingVectorAsync(*(void**)(&prompt), *(void**)(&contentFilterOptions), &operation));
        return winrt::Windows::Foundation::IAsyncOperation<winrt::Windows::Foundation::Collections::IVectorView<winrt::Microsoft::Windows::SemanticSearch::EmbeddingVector>>{ operation, take_ownership_from_abi };
    }
    template <typename D> auto consume_Microsoft_Windows_AI_Generative_ILanguageModel5<D>::GenerateTokens(param::hstring const& text, winrt::Microsoft::Windows::AI::ContentModeration::ContentFilterOptions const& contentFilterOptions) const
    {
        void* result{};
        check_hresult(WINRT_IMPL_SHIM(winrt::Microsoft::Windows::AI::Generative::ILanguageModel5)->GenerateTokens(*(void**)(&text), *(void**)(&contentFilterOptions), &result));
        return winrt::Windows::Foundation::Collections::IVectorView<int64_t>{ result, take_ownership_from_abi };
    }
    template <typename D> auto consume_Microsoft_Windows_AI_Generative_ILanguageModel5<D>::GenerateTokensAsync(param::hstring const& text, winrt::Microsoft::Windows::AI::ContentModeration::ContentFilterOptions const& contentFilterOptions) const
    {
        void* operation{};
        check_hresult(WINRT_IMPL_SHIM(winrt::Microsoft::Windows::AI::Generative::ILanguageModel5)->GenerateTokensAsync(*(void**)(&text), *(void**)(&contentFilterOptions), &operation));
        return winrt::Windows::Foundation::IAsyncOperation<winrt::Windows::Foundation::Collections::IVectorView<int64_t>>{ operation, take_ownership_from_abi };
    }
    template <typename D> auto consume_Microsoft_Windows_AI_Generative_ILanguageModel5<D>::CreateContext() const
    {
        void* result{};
        check_hresult(WINRT_IMPL_SHIM(winrt::Microsoft::Windows::AI::Generative::ILanguageModel5)->CreateContext(&result));
        return winrt::Microsoft::Windows::AI::Generative::LanguageModelContext{ result, take_ownership_from_abi };
    }
    template <typename D> auto consume_Microsoft_Windows_AI_Generative_ILanguageModel5<D>::CreateContext(param::hstring const& systemPrompt, winrt::Microsoft::Windows::AI::ContentModeration::ContentFilterOptions const& contentFilterOptions) const
    {
        void* result{};
        check_hresult(WINRT_IMPL_SHIM(winrt::Microsoft::Windows::AI::Generative::ILanguageModel5)->CreateContext2(*(void**)(&systemPrompt), *(void**)(&contentFilterOptions), &result));
        return winrt::Microsoft::Windows::AI::Generative::LanguageModelContext{ result, take_ownership_from_abi };
    }
    template <typename D> auto consume_Microsoft_Windows_AI_Generative_ILanguageModel5<D>::IsPromptLargerThanContext(winrt::Microsoft::Windows::AI::Generative::LanguageModelContext const& context, param::hstring const& prompt) const
    {
        bool result{};
        check_hresult(WINRT_IMPL_SHIM(winrt::Microsoft::Windows::AI::Generative::ILanguageModel5)->IsPromptLargerThanContext(*(void**)(&context), *(void**)(&prompt), &result));
        return result;
    }
    template <typename D> auto consume_Microsoft_Windows_AI_Generative_ILanguageModelOptions<D>::Skill() const
    {
        winrt::Microsoft::Windows::AI::Generative::LanguageModelSkill value{};
        check_hresult(WINRT_IMPL_SHIM(winrt::Microsoft::Windows::AI::Generative::ILanguageModelOptions)->get_Skill(reinterpret_cast<int32_t*>(&value)));
        return value;
    }
    template <typename D> auto consume_Microsoft_Windows_AI_Generative_ILanguageModelOptions<D>::Skill(winrt::Microsoft::Windows::AI::Generative::LanguageModelSkill const& value) const
    {
        check_hresult(WINRT_IMPL_SHIM(winrt::Microsoft::Windows::AI::Generative::ILanguageModelOptions)->put_Skill(static_cast<int32_t>(value)));
    }
    template <typename D> auto consume_Microsoft_Windows_AI_Generative_ILanguageModelOptions<D>::Temp() const
    {
        float value{};
        check_hresult(WINRT_IMPL_SHIM(winrt::Microsoft::Windows::AI::Generative::ILanguageModelOptions)->get_Temp(&value));
        return value;
    }
    template <typename D> auto consume_Microsoft_Windows_AI_Generative_ILanguageModelOptions<D>::Temp(float value) const
    {
        check_hresult(WINRT_IMPL_SHIM(winrt::Microsoft::Windows::AI::Generative::ILanguageModelOptions)->put_Temp(value));
    }
    template <typename D> auto consume_Microsoft_Windows_AI_Generative_ILanguageModelOptions<D>::Top_p() const
    {
        float value{};
        check_hresult(WINRT_IMPL_SHIM(winrt::Microsoft::Windows::AI::Generative::ILanguageModelOptions)->get_Top_p(&value));
        return value;
    }
    template <typename D> auto consume_Microsoft_Windows_AI_Generative_ILanguageModelOptions<D>::Top_p(float value) const
    {
        check_hresult(WINRT_IMPL_SHIM(winrt::Microsoft::Windows::AI::Generative::ILanguageModelOptions)->put_Top_p(value));
    }
    template <typename D> auto consume_Microsoft_Windows_AI_Generative_ILanguageModelOptions<D>::Top_k() const
    {
        uint32_t value{};
        check_hresult(WINRT_IMPL_SHIM(winrt::Microsoft::Windows::AI::Generative::ILanguageModelOptions)->get_Top_k(&value));
        return value;
    }
    template <typename D> auto consume_Microsoft_Windows_AI_Generative_ILanguageModelOptions<D>::Top_k(uint32_t value) const
    {
        check_hresult(WINRT_IMPL_SHIM(winrt::Microsoft::Windows::AI::Generative::ILanguageModelOptions)->put_Top_k(value));
    }
    template <typename D> auto consume_Microsoft_Windows_AI_Generative_ILanguageModelOptionsFactory<D>::CreateInstance(winrt::Microsoft::Windows::AI::Generative::LanguageModelSkill const& skill, float temp, float top_p, uint32_t top_k) const
    {
        void* value{};
        check_hresult(WINRT_IMPL_SHIM(winrt::Microsoft::Windows::AI::Generative::ILanguageModelOptionsFactory)->CreateInstance(static_cast<int32_t>(skill), temp, top_p, top_k, &value));
        return winrt::Microsoft::Windows::AI::Generative::LanguageModelOptions{ value, take_ownership_from_abi };
    }
    template <typename D> auto consume_Microsoft_Windows_AI_Generative_ILanguageModelResponse<D>::Response() const
    {
        void* value{};
        check_hresult(WINRT_IMPL_SHIM(winrt::Microsoft::Windows::AI::Generative::ILanguageModelResponse)->get_Response(&value));
        return hstring{ value, take_ownership_from_abi };
    }
    template <typename D> auto consume_Microsoft_Windows_AI_Generative_ILanguageModelResponse<D>::Status() const
    {
        winrt::Microsoft::Windows::AI::Generative::LanguageModelResponseStatus value{};
        check_hresult(WINRT_IMPL_SHIM(winrt::Microsoft::Windows::AI::Generative::ILanguageModelResponse)->get_Status(reinterpret_cast<int32_t*>(&value)));
        return value;
    }
    template <typename D> auto consume_Microsoft_Windows_AI_Generative_ILanguageModelResponseFactory<D>::CreateInstance(param::hstring const& response, winrt::Microsoft::Windows::AI::Generative::LanguageModelResponseStatus const& status) const
    {
        void* value{};
        check_hresult(WINRT_IMPL_SHIM(winrt::Microsoft::Windows::AI::Generative::ILanguageModelResponseFactory)->CreateInstance(*(void**)(&response), static_cast<int32_t>(status), &value));
        return winrt::Microsoft::Windows::AI::Generative::LanguageModelResponse{ value, take_ownership_from_abi };
    }
    template <typename D> auto consume_Microsoft_Windows_AI_Generative_ILanguageModelStatics<D>::IsAvailable() const
    {
        bool result{};
        check_hresult(WINRT_IMPL_SHIM(winrt::Microsoft::Windows::AI::Generative::ILanguageModelStatics)->IsAvailable(&result));
        return result;
    }
    template <typename D> auto consume_Microsoft_Windows_AI_Generative_ILanguageModelStatics<D>::MakeAvailableAsync() const
    {
        void* operation{};
        check_hresult(WINRT_IMPL_SHIM(winrt::Microsoft::Windows::AI::Generative::ILanguageModelStatics)->MakeAvailableAsync(&operation));
        return winrt::Windows::Foundation::IAsyncOperationWithProgress<winrt::Microsoft::Windows::Management::Deployment::PackageDeploymentResult, winrt::Microsoft::Windows::Management::Deployment::PackageDeploymentProgress>{ operation, take_ownership_from_abi };
    }
    template <typename D> auto consume_Microsoft_Windows_AI_Generative_ILanguageModelStatics<D>::CreateAsync() const
    {
        void* operation{};
        check_hresult(WINRT_IMPL_SHIM(winrt::Microsoft::Windows::AI::Generative::ILanguageModelStatics)->CreateAsync(&operation));
        return winrt::Windows::Foundation::IAsyncOperation<winrt::Microsoft::Windows::AI::Generative::LanguageModel>{ operation, take_ownership_from_abi };
    }
#ifndef WINRT_LEAN_AND_MEAN
    template <typename D>
    struct produce<D, winrt::Microsoft::Windows::AI::Generative::IImageDescriptionGenerator> : produce_base<D, winrt::Microsoft::Windows::AI::Generative::IImageDescriptionGenerator>
    {
        int32_t __stdcall DescribeAsync(void* image, void** operation) noexcept final try
        {
            clear_abi(operation);
            typename D::abi_guard guard(this->shim());
            *operation = detach_from<winrt::Windows::Foundation::IAsyncOperationWithProgress<winrt::Microsoft::Windows::AI::Generative::LanguageModelResponse, hstring>>(this->shim().DescribeAsync(*reinterpret_cast<winrt::Microsoft::Graphics::Imaging::ImageBuffer const*>(&image)));
            return 0;
        }
        catch (...) { return to_hresult(); }
    };
#endif
#ifndef WINRT_LEAN_AND_MEAN
    template <typename D>
    struct produce<D, winrt::Microsoft::Windows::AI::Generative::IImageDescriptionGenerator2> : produce_base<D, winrt::Microsoft::Windows::AI::Generative::IImageDescriptionGenerator2>
    {
        int32_t __stdcall DescribeAsync(void* image, int32_t scenario, void** operation) noexcept final try
        {
            clear_abi(operation);
            typename D::abi_guard guard(this->shim());
            *operation = detach_from<winrt::Windows::Foundation::IAsyncOperationWithProgress<winrt::Microsoft::Windows::AI::Generative::LanguageModelResponse, hstring>>(this->shim().DescribeAsync(*reinterpret_cast<winrt::Microsoft::Graphics::Imaging::ImageBuffer const*>(&image), *reinterpret_cast<winrt::Microsoft::Windows::AI::Generative::ImageDescriptionScenario const*>(&scenario)));
            return 0;
        }
        catch (...) { return to_hresult(); }
    };
#endif
#ifndef WINRT_LEAN_AND_MEAN
    template <typename D>
    struct produce<D, winrt::Microsoft::Windows::AI::Generative::IImageDescriptionGenerator3> : produce_base<D, winrt::Microsoft::Windows::AI::Generative::IImageDescriptionGenerator3>
    {
        int32_t __stdcall DescribeAsync(void* image, int32_t scenario, void* contentFilterOptions, void** operation) noexcept final try
        {
            clear_abi(operation);
            typename D::abi_guard guard(this->shim());
            *operation = detach_from<winrt::Windows::Foundation::IAsyncOperationWithProgress<winrt::Microsoft::Windows::AI::Generative::LanguageModelResponse, hstring>>(this->shim().DescribeAsync(*reinterpret_cast<winrt::Microsoft::Graphics::Imaging::ImageBuffer const*>(&image), *reinterpret_cast<winrt::Microsoft::Windows::AI::Generative::ImageDescriptionScenario const*>(&scenario), *reinterpret_cast<winrt::Microsoft::Windows::AI::ContentModeration::ContentFilterOptions const*>(&contentFilterOptions)));
            return 0;
        }
        catch (...) { return to_hresult(); }
    };
#endif
#ifndef WINRT_LEAN_AND_MEAN
    template <typename D>
    struct produce<D, winrt::Microsoft::Windows::AI::Generative::IImageDescriptionGeneratorStatics> : produce_base<D, winrt::Microsoft::Windows::AI::Generative::IImageDescriptionGeneratorStatics>
    {
        int32_t __stdcall IsAvailable(bool* result) noexcept final try
        {
            typename D::abi_guard guard(this->shim());
            *result = detach_from<bool>(this->shim().IsAvailable());
            return 0;
        }
        catch (...) { return to_hresult(); }
        int32_t __stdcall MakeAvailableAsync(void** operation) noexcept final try
        {
            clear_abi(operation);
            typename D::abi_guard guard(this->shim());
            *operation = detach_from<winrt::Windows::Foundation::IAsyncOperationWithProgress<winrt::Microsoft::Windows::Management::Deployment::PackageDeploymentResult, winrt::Microsoft::Windows::Management::Deployment::PackageDeploymentProgress>>(this->shim().MakeAvailableAsync());
            return 0;
        }
        catch (...) { return to_hresult(); }
        int32_t __stdcall CreateAsync(void** operation) noexcept final try
        {
            clear_abi(operation);
            typename D::abi_guard guard(this->shim());
            *operation = detach_from<winrt::Windows::Foundation::IAsyncOperation<winrt::Microsoft::Windows::AI::Generative::ImageDescriptionGenerator>>(this->shim().CreateAsync());
            return 0;
        }
        catch (...) { return to_hresult(); }
    };
#endif
#ifndef WINRT_LEAN_AND_MEAN
    template <typename D>
    struct produce<D, winrt::Microsoft::Windows::AI::Generative::ILanguageModel> : produce_base<D, winrt::Microsoft::Windows::AI::Generative::ILanguageModel>
    {
        int32_t __stdcall GenerateResponseAsync(void* prompt, void** operation) noexcept final try
        {
            clear_abi(operation);
            typename D::abi_guard guard(this->shim());
            *operation = detach_from<winrt::Windows::Foundation::IAsyncOperation<winrt::Microsoft::Windows::AI::Generative::LanguageModelResponse>>(this->shim().GenerateResponseAsync(*reinterpret_cast<hstring const*>(&prompt)));
            return 0;
        }
        catch (...) { return to_hresult(); }
        int32_t __stdcall GenerateResponseWithProgressAsync(void* prompt, void** operation) noexcept final try
        {
            clear_abi(operation);
            typename D::abi_guard guard(this->shim());
            *operation = detach_from<winrt::Windows::Foundation::IAsyncOperationWithProgress<winrt::Microsoft::Windows::AI::Generative::LanguageModelResponse, hstring>>(this->shim().GenerateResponseWithProgressAsync(*reinterpret_cast<hstring const*>(&prompt)));
            return 0;
        }
        catch (...) { return to_hresult(); }
    };
#endif
#ifndef WINRT_LEAN_AND_MEAN
    template <typename D>
    struct produce<D, winrt::Microsoft::Windows::AI::Generative::ILanguageModel2> : produce_base<D, winrt::Microsoft::Windows::AI::Generative::ILanguageModel2>
    {
        int32_t __stdcall GenerateResponseFromEmbeddingsWithProgressAsync(void* promptEmbedding, void** operation) noexcept final try
        {
            clear_abi(operation);
            typename D::abi_guard guard(this->shim());
            *operation = detach_from<winrt::Windows::Foundation::IAsyncOperationWithProgress<winrt::Microsoft::Windows::AI::Generative::LanguageModelResponse, hstring>>(this->shim().GenerateResponseFromEmbeddingsWithProgressAsync(*reinterpret_cast<winrt::Windows::Foundation::Collections::IVectorView<winrt::Microsoft::Windows::SemanticSearch::EmbeddingVector> const*>(&promptEmbedding)));
            return 0;
        }
        catch (...) { return to_hresult(); }
        int32_t __stdcall GenerateEmbeddingVector(void* prompt, void** result) noexcept final try
        {
            clear_abi(result);
            typename D::abi_guard guard(this->shim());
            *result = detach_from<winrt::Windows::Foundation::Collections::IVectorView<winrt::Microsoft::Windows::SemanticSearch::EmbeddingVector>>(this->shim().GenerateEmbeddingVector(*reinterpret_cast<hstring const*>(&prompt)));
            return 0;
        }
        catch (...) { return to_hresult(); }
        int32_t __stdcall GenerateEmbeddingVectorAsync(void* prompt, void** operation) noexcept final try
        {
            clear_abi(operation);
            typename D::abi_guard guard(this->shim());
            *operation = detach_from<winrt::Windows::Foundation::IAsyncOperation<winrt::Windows::Foundation::Collections::IVectorView<winrt::Microsoft::Windows::SemanticSearch::EmbeddingVector>>>(this->shim().GenerateEmbeddingVectorAsync(*reinterpret_cast<hstring const*>(&prompt)));
            return 0;
        }
        catch (...) { return to_hresult(); }
        int32_t __stdcall IsPromptLargerThanContext(void* prompt, bool* result) noexcept final try
        {
            typename D::abi_guard guard(this->shim());
            *result = detach_from<bool>(this->shim().IsPromptLargerThanContext(*reinterpret_cast<hstring const*>(&prompt)));
            return 0;
        }
        catch (...) { return to_hresult(); }
    };
#endif
#ifndef WINRT_LEAN_AND_MEAN
    template <typename D>
    struct produce<D, winrt::Microsoft::Windows::AI::Generative::ILanguageModel3> : produce_base<D, winrt::Microsoft::Windows::AI::Generative::ILanguageModel3>
    {
        int32_t __stdcall GenerateResponseAsync(void* options, void* prompt, void** operation) noexcept final try
        {
            clear_abi(operation);
            typename D::abi_guard guard(this->shim());
            *operation = detach_from<winrt::Windows::Foundation::IAsyncOperation<winrt::Microsoft::Windows::AI::Generative::LanguageModelResponse>>(this->shim().GenerateResponseAsync(*reinterpret_cast<winrt::Microsoft::Windows::AI::Generative::LanguageModelOptions const*>(&options), *reinterpret_cast<hstring const*>(&prompt)));
            return 0;
        }
        catch (...) { return to_hresult(); }
        int32_t __stdcall GenerateResponseFromEmbeddingsWithProgressAsync(void* options, void* promptEmbedding, void** operation) noexcept final try
        {
            clear_abi(operation);
            typename D::abi_guard guard(this->shim());
            *operation = detach_from<winrt::Windows::Foundation::IAsyncOperationWithProgress<winrt::Microsoft::Windows::AI::Generative::LanguageModelResponse, hstring>>(this->shim().GenerateResponseFromEmbeddingsWithProgressAsync(*reinterpret_cast<winrt::Microsoft::Windows::AI::Generative::LanguageModelOptions const*>(&options), *reinterpret_cast<winrt::Windows::Foundation::Collections::IVectorView<winrt::Microsoft::Windows::SemanticSearch::EmbeddingVector> const*>(&promptEmbedding)));
            return 0;
        }
        catch (...) { return to_hresult(); }
    };
#endif
#ifndef WINRT_LEAN_AND_MEAN
    template <typename D>
    struct produce<D, winrt::Microsoft::Windows::AI::Generative::ILanguageModel4> : produce_base<D, winrt::Microsoft::Windows::AI::Generative::ILanguageModel4>
    {
        int32_t __stdcall GenerateResponseWithProgressAsync(void* options, void* prompt, void** operation) noexcept final try
        {
            clear_abi(operation);
            typename D::abi_guard guard(this->shim());
            *operation = detach_from<winrt::Windows::Foundation::IAsyncOperationWithProgress<winrt::Microsoft::Windows::AI::Generative::LanguageModelResponse, hstring>>(this->shim().GenerateResponseWithProgressAsync(*reinterpret_cast<winrt::Microsoft::Windows::AI::Generative::LanguageModelOptions const*>(&options), *reinterpret_cast<hstring const*>(&prompt)));
            return 0;
        }
        catch (...) { return to_hresult(); }
        int32_t __stdcall GenerateTokens(void* text, void** result) noexcept final try
        {
            clear_abi(result);
            typename D::abi_guard guard(this->shim());
            *result = detach_from<winrt::Windows::Foundation::Collections::IVectorView<int64_t>>(this->shim().GenerateTokens(*reinterpret_cast<hstring const*>(&text)));
            return 0;
        }
        catch (...) { return to_hresult(); }
        int32_t __stdcall GenerateTokensAsync(void* text, void** operation) noexcept final try
        {
            clear_abi(operation);
            typename D::abi_guard guard(this->shim());
            *operation = detach_from<winrt::Windows::Foundation::IAsyncOperation<winrt::Windows::Foundation::Collections::IVectorView<int64_t>>>(this->shim().GenerateTokensAsync(*reinterpret_cast<hstring const*>(&text)));
            return 0;
        }
        catch (...) { return to_hresult(); }
        int32_t __stdcall GenerateResponseFromTokensWithProgressAsync(void* options, void* promptTokens, void** operation) noexcept final try
        {
            clear_abi(operation);
            typename D::abi_guard guard(this->shim());
            *operation = detach_from<winrt::Windows::Foundation::IAsyncOperationWithProgress<winrt::Microsoft::Windows::AI::Generative::LanguageModelResponse, hstring>>(this->shim().GenerateResponseFromTokensWithProgressAsync(*reinterpret_cast<winrt::Microsoft::Windows::AI::Generative::LanguageModelOptions const*>(&options), *reinterpret_cast<winrt::Windows::Foundation::Collections::IVectorView<int64_t> const*>(&promptTokens)));
            return 0;
        }
        catch (...) { return to_hresult(); }
    };
#endif
#ifndef WINRT_LEAN_AND_MEAN
    template <typename D>
    struct produce<D, winrt::Microsoft::Windows::AI::Generative::ILanguageModel5> : produce_base<D, winrt::Microsoft::Windows::AI::Generative::ILanguageModel5>
    {
        int32_t __stdcall GenerateResponseAsync(void* options, void* prompt, void* contentFilterOptions, void** operation) noexcept final try
        {
            clear_abi(operation);
            typename D::abi_guard guard(this->shim());
            *operation = detach_from<winrt::Windows::Foundation::IAsyncOperation<winrt::Microsoft::Windows::AI::Generative::LanguageModelResponse>>(this->shim().GenerateResponseAsync(*reinterpret_cast<winrt::Microsoft::Windows::AI::Generative::LanguageModelOptions const*>(&options), *reinterpret_cast<hstring const*>(&prompt), *reinterpret_cast<winrt::Microsoft::Windows::AI::ContentModeration::ContentFilterOptions const*>(&contentFilterOptions)));
            return 0;
        }
        catch (...) { return to_hresult(); }
        int32_t __stdcall GenerateResponseWithProgressAsync(void* options, void* prompt, void* contentFilterOptions, void** operation) noexcept final try
        {
            clear_abi(operation);
            typename D::abi_guard guard(this->shim());
            *operation = detach_from<winrt::Windows::Foundation::IAsyncOperationWithProgress<winrt::Microsoft::Windows::AI::Generative::LanguageModelResponse, hstring>>(this->shim().GenerateResponseWithProgressAsync(*reinterpret_cast<winrt::Microsoft::Windows::AI::Generative::LanguageModelOptions const*>(&options), *reinterpret_cast<hstring const*>(&prompt), *reinterpret_cast<winrt::Microsoft::Windows::AI::ContentModeration::ContentFilterOptions const*>(&contentFilterOptions)));
            return 0;
        }
        catch (...) { return to_hresult(); }
        int32_t __stdcall GenerateResponseFromEmbeddingsWithProgressAsync(void* options, void* promptEmbedding, void* contentFilterOptions, void** operation) noexcept final try
        {
            clear_abi(operation);
            typename D::abi_guard guard(this->shim());
            *operation = detach_from<winrt::Windows::Foundation::IAsyncOperationWithProgress<winrt::Microsoft::Windows::AI::Generative::LanguageModelResponse, hstring>>(this->shim().GenerateResponseFromEmbeddingsWithProgressAsync(*reinterpret_cast<winrt::Microsoft::Windows::AI::Generative::LanguageModelOptions const*>(&options), *reinterpret_cast<winrt::Windows::Foundation::Collections::IVectorView<winrt::Microsoft::Windows::SemanticSearch::EmbeddingVector> const*>(&promptEmbedding), *reinterpret_cast<winrt::Microsoft::Windows::AI::ContentModeration::ContentFilterOptions const*>(&contentFilterOptions)));
            return 0;
        }
        catch (...) { return to_hresult(); }
        int32_t __stdcall GenerateResponseFromTokensWithProgressAsync(void* options, void* promptTokens, void* contentFilterOptions, void** operation) noexcept final try
        {
            clear_abi(operation);
            typename D::abi_guard guard(this->shim());
            *operation = detach_from<winrt::Windows::Foundation::IAsyncOperationWithProgress<winrt::Microsoft::Windows::AI::Generative::LanguageModelResponse, hstring>>(this->shim().GenerateResponseFromTokensWithProgressAsync(*reinterpret_cast<winrt::Microsoft::Windows::AI::Generative::LanguageModelOptions const*>(&options), *reinterpret_cast<winrt::Windows::Foundation::Collections::IVectorView<int64_t> const*>(&promptTokens), *reinterpret_cast<winrt::Microsoft::Windows::AI::ContentModeration::ContentFilterOptions const*>(&contentFilterOptions)));
            return 0;
        }
        catch (...) { return to_hresult(); }
        int32_t __stdcall GenerateResponseAsync2(void* options, void* prompt, void* contentFilterOptions, void* context, void** operation) noexcept final try
        {
            clear_abi(operation);
            typename D::abi_guard guard(this->shim());
            *operation = detach_from<winrt::Windows::Foundation::IAsyncOperation<winrt::Microsoft::Windows::AI::Generative::LanguageModelResponse>>(this->shim().GenerateResponseAsync(*reinterpret_cast<winrt::Microsoft::Windows::AI::Generative::LanguageModelOptions const*>(&options), *reinterpret_cast<hstring const*>(&prompt), *reinterpret_cast<winrt::Microsoft::Windows::AI::ContentModeration::ContentFilterOptions const*>(&contentFilterOptions), *reinterpret_cast<winrt::Microsoft::Windows::AI::Generative::LanguageModelContext const*>(&context)));
            return 0;
        }
        catch (...) { return to_hresult(); }
        int32_t __stdcall GenerateResponseWithProgressAsync2(void* options, void* prompt, void* contentFilterOptions, void* context, void** operation) noexcept final try
        {
            clear_abi(operation);
            typename D::abi_guard guard(this->shim());
            *operation = detach_from<winrt::Windows::Foundation::IAsyncOperationWithProgress<winrt::Microsoft::Windows::AI::Generative::LanguageModelResponse, hstring>>(this->shim().GenerateResponseWithProgressAsync(*reinterpret_cast<winrt::Microsoft::Windows::AI::Generative::LanguageModelOptions const*>(&options), *reinterpret_cast<hstring const*>(&prompt), *reinterpret_cast<winrt::Microsoft::Windows::AI::ContentModeration::ContentFilterOptions const*>(&contentFilterOptions), *reinterpret_cast<winrt::Microsoft::Windows::AI::Generative::LanguageModelContext const*>(&context)));
            return 0;
        }
        catch (...) { return to_hresult(); }
        int32_t __stdcall GenerateResponseFromEmbeddingsWithProgressAsync2(void* options, void* promptEmbedding, void* contentFilterOptions, void* context, void** operation) noexcept final try
        {
            clear_abi(operation);
            typename D::abi_guard guard(this->shim());
            *operation = detach_from<winrt::Windows::Foundation::IAsyncOperationWithProgress<winrt::Microsoft::Windows::AI::Generative::LanguageModelResponse, hstring>>(this->shim().GenerateResponseFromEmbeddingsWithProgressAsync(*reinterpret_cast<winrt::Microsoft::Windows::AI::Generative::LanguageModelOptions const*>(&options), *reinterpret_cast<winrt::Windows::Foundation::Collections::IVectorView<winrt::Microsoft::Windows::SemanticSearch::EmbeddingVector> const*>(&promptEmbedding), *reinterpret_cast<winrt::Microsoft::Windows::AI::ContentModeration::ContentFilterOptions const*>(&contentFilterOptions), *reinterpret_cast<winrt::Microsoft::Windows::AI::Generative::LanguageModelContext const*>(&context)));
            return 0;
        }
        catch (...) { return to_hresult(); }
        int32_t __stdcall GenerateResponseFromTokensWithProgressAsync2(void* options, void* promptTokens, void* contentFilterOptions, void* context, void** operation) noexcept final try
        {
            clear_abi(operation);
            typename D::abi_guard guard(this->shim());
            *operation = detach_from<winrt::Windows::Foundation::IAsyncOperationWithProgress<winrt::Microsoft::Windows::AI::Generative::LanguageModelResponse, hstring>>(this->shim().GenerateResponseFromTokensWithProgressAsync(*reinterpret_cast<winrt::Microsoft::Windows::AI::Generative::LanguageModelOptions const*>(&options), *reinterpret_cast<winrt::Windows::Foundation::Collections::IVectorView<int64_t> const*>(&promptTokens), *reinterpret_cast<winrt::Microsoft::Windows::AI::ContentModeration::ContentFilterOptions const*>(&contentFilterOptions), *reinterpret_cast<winrt::Microsoft::Windows::AI::Generative::LanguageModelContext const*>(&context)));
            return 0;
        }
        catch (...) { return to_hresult(); }
        int32_t __stdcall GenerateEmbeddingVector(void* prompt, void* contentFilterOptions, void** result) noexcept final try
        {
            clear_abi(result);
            typename D::abi_guard guard(this->shim());
            *result = detach_from<winrt::Windows::Foundation::Collections::IVectorView<winrt::Microsoft::Windows::SemanticSearch::EmbeddingVector>>(this->shim().GenerateEmbeddingVector(*reinterpret_cast<hstring const*>(&prompt), *reinterpret_cast<winrt::Microsoft::Windows::AI::ContentModeration::ContentFilterOptions const*>(&contentFilterOptions)));
            return 0;
        }
        catch (...) { return to_hresult(); }
        int32_t __stdcall GenerateEmbeddingVectorAsync(void* prompt, void* contentFilterOptions, void** operation) noexcept final try
        {
            clear_abi(operation);
            typename D::abi_guard guard(this->shim());
            *operation = detach_from<winrt::Windows::Foundation::IAsyncOperation<winrt::Windows::Foundation::Collections::IVectorView<winrt::Microsoft::Windows::SemanticSearch::EmbeddingVector>>>(this->shim().GenerateEmbeddingVectorAsync(*reinterpret_cast<hstring const*>(&prompt), *reinterpret_cast<winrt::Microsoft::Windows::AI::ContentModeration::ContentFilterOptions const*>(&contentFilterOptions)));
            return 0;
        }
        catch (...) { return to_hresult(); }
        int32_t __stdcall GenerateTokens(void* text, void* contentFilterOptions, void** result) noexcept final try
        {
            clear_abi(result);
            typename D::abi_guard guard(this->shim());
            *result = detach_from<winrt::Windows::Foundation::Collections::IVectorView<int64_t>>(this->shim().GenerateTokens(*reinterpret_cast<hstring const*>(&text), *reinterpret_cast<winrt::Microsoft::Windows::AI::ContentModeration::ContentFilterOptions const*>(&contentFilterOptions)));
            return 0;
        }
        catch (...) { return to_hresult(); }
        int32_t __stdcall GenerateTokensAsync(void* text, void* contentFilterOptions, void** operation) noexcept final try
        {
            clear_abi(operation);
            typename D::abi_guard guard(this->shim());
            *operation = detach_from<winrt::Windows::Foundation::IAsyncOperation<winrt::Windows::Foundation::Collections::IVectorView<int64_t>>>(this->shim().GenerateTokensAsync(*reinterpret_cast<hstring const*>(&text), *reinterpret_cast<winrt::Microsoft::Windows::AI::ContentModeration::ContentFilterOptions const*>(&contentFilterOptions)));
            return 0;
        }
        catch (...) { return to_hresult(); }
        int32_t __stdcall CreateContext(void** result) noexcept final try
        {
            clear_abi(result);
            typename D::abi_guard guard(this->shim());
            *result = detach_from<winrt::Microsoft::Windows::AI::Generative::LanguageModelContext>(this->shim().CreateContext());
            return 0;
        }
        catch (...) { return to_hresult(); }
        int32_t __stdcall CreateContext2(void* systemPrompt, void* contentFilterOptions, void** result) noexcept final try
        {
            clear_abi(result);
            typename D::abi_guard guard(this->shim());
            *result = detach_from<winrt::Microsoft::Windows::AI::Generative::LanguageModelContext>(this->shim().CreateContext(*reinterpret_cast<hstring const*>(&systemPrompt), *reinterpret_cast<winrt::Microsoft::Windows::AI::ContentModeration::ContentFilterOptions const*>(&contentFilterOptions)));
            return 0;
        }
        catch (...) { return to_hresult(); }
        int32_t __stdcall IsPromptLargerThanContext(void* context, void* prompt, bool* result) noexcept final try
        {
            typename D::abi_guard guard(this->shim());
            *result = detach_from<bool>(this->shim().IsPromptLargerThanContext(*reinterpret_cast<winrt::Microsoft::Windows::AI::Generative::LanguageModelContext const*>(&context), *reinterpret_cast<hstring const*>(&prompt)));
            return 0;
        }
        catch (...) { return to_hresult(); }
    };
#endif
#ifndef WINRT_LEAN_AND_MEAN
    template <typename D>
    struct produce<D, winrt::Microsoft::Windows::AI::Generative::ILanguageModelContext> : produce_base<D, winrt::Microsoft::Windows::AI::Generative::ILanguageModelContext>
    {
    };
#endif
#ifndef WINRT_LEAN_AND_MEAN
    template <typename D>
    struct produce<D, winrt::Microsoft::Windows::AI::Generative::ILanguageModelOptions> : produce_base<D, winrt::Microsoft::Windows::AI::Generative::ILanguageModelOptions>
    {
        int32_t __stdcall get_Skill(int32_t* value) noexcept final try
        {
            typename D::abi_guard guard(this->shim());
            *value = detach_from<winrt::Microsoft::Windows::AI::Generative::LanguageModelSkill>(this->shim().Skill());
            return 0;
        }
        catch (...) { return to_hresult(); }
        int32_t __stdcall put_Skill(int32_t value) noexcept final try
        {
            typename D::abi_guard guard(this->shim());
            this->shim().Skill(*reinterpret_cast<winrt::Microsoft::Windows::AI::Generative::LanguageModelSkill const*>(&value));
            return 0;
        }
        catch (...) { return to_hresult(); }
        int32_t __stdcall get_Temp(float* value) noexcept final try
        {
            typename D::abi_guard guard(this->shim());
            *value = detach_from<float>(this->shim().Temp());
            return 0;
        }
        catch (...) { return to_hresult(); }
        int32_t __stdcall put_Temp(float value) noexcept final try
        {
            typename D::abi_guard guard(this->shim());
            this->shim().Temp(value);
            return 0;
        }
        catch (...) { return to_hresult(); }
        int32_t __stdcall get_Top_p(float* value) noexcept final try
        {
            typename D::abi_guard guard(this->shim());
            *value = detach_from<float>(this->shim().Top_p());
            return 0;
        }
        catch (...) { return to_hresult(); }
        int32_t __stdcall put_Top_p(float value) noexcept final try
        {
            typename D::abi_guard guard(this->shim());
            this->shim().Top_p(value);
            return 0;
        }
        catch (...) { return to_hresult(); }
        int32_t __stdcall get_Top_k(uint32_t* value) noexcept final try
        {
            typename D::abi_guard guard(this->shim());
            *value = detach_from<uint32_t>(this->shim().Top_k());
            return 0;
        }
        catch (...) { return to_hresult(); }
        int32_t __stdcall put_Top_k(uint32_t value) noexcept final try
        {
            typename D::abi_guard guard(this->shim());
            this->shim().Top_k(value);
            return 0;
        }
        catch (...) { return to_hresult(); }
    };
#endif
#ifndef WINRT_LEAN_AND_MEAN
    template <typename D>
    struct produce<D, winrt::Microsoft::Windows::AI::Generative::ILanguageModelOptionsFactory> : produce_base<D, winrt::Microsoft::Windows::AI::Generative::ILanguageModelOptionsFactory>
    {
        int32_t __stdcall CreateInstance(int32_t skill, float temp, float top_p, uint32_t top_k, void** value) noexcept final try
        {
            clear_abi(value);
            typename D::abi_guard guard(this->shim());
            *value = detach_from<winrt::Microsoft::Windows::AI::Generative::LanguageModelOptions>(this->shim().CreateInstance(*reinterpret_cast<winrt::Microsoft::Windows::AI::Generative::LanguageModelSkill const*>(&skill), temp, top_p, top_k));
            return 0;
        }
        catch (...) { return to_hresult(); }
    };
#endif
#ifndef WINRT_LEAN_AND_MEAN
    template <typename D>
    struct produce<D, winrt::Microsoft::Windows::AI::Generative::ILanguageModelResponse> : produce_base<D, winrt::Microsoft::Windows::AI::Generative::ILanguageModelResponse>
    {
        int32_t __stdcall get_Response(void** value) noexcept final try
        {
            clear_abi(value);
            typename D::abi_guard guard(this->shim());
            *value = detach_from<hstring>(this->shim().Response());
            return 0;
        }
        catch (...) { return to_hresult(); }
        int32_t __stdcall get_Status(int32_t* value) noexcept final try
        {
            typename D::abi_guard guard(this->shim());
            *value = detach_from<winrt::Microsoft::Windows::AI::Generative::LanguageModelResponseStatus>(this->shim().Status());
            return 0;
        }
        catch (...) { return to_hresult(); }
    };
#endif
#ifndef WINRT_LEAN_AND_MEAN
    template <typename D>
    struct produce<D, winrt::Microsoft::Windows::AI::Generative::ILanguageModelResponseFactory> : produce_base<D, winrt::Microsoft::Windows::AI::Generative::ILanguageModelResponseFactory>
    {
        int32_t __stdcall CreateInstance(void* response, int32_t status, void** value) noexcept final try
        {
            clear_abi(value);
            typename D::abi_guard guard(this->shim());
            *value = detach_from<winrt::Microsoft::Windows::AI::Generative::LanguageModelResponse>(this->shim().CreateInstance(*reinterpret_cast<hstring const*>(&response), *reinterpret_cast<winrt::Microsoft::Windows::AI::Generative::LanguageModelResponseStatus const*>(&status)));
            return 0;
        }
        catch (...) { return to_hresult(); }
    };
#endif
#ifndef WINRT_LEAN_AND_MEAN
    template <typename D>
    struct produce<D, winrt::Microsoft::Windows::AI::Generative::ILanguageModelStatics> : produce_base<D, winrt::Microsoft::Windows::AI::Generative::ILanguageModelStatics>
    {
        int32_t __stdcall IsAvailable(bool* result) noexcept final try
        {
            typename D::abi_guard guard(this->shim());
            *result = detach_from<bool>(this->shim().IsAvailable());
            return 0;
        }
        catch (...) { return to_hresult(); }
        int32_t __stdcall MakeAvailableAsync(void** operation) noexcept final try
        {
            clear_abi(operation);
            typename D::abi_guard guard(this->shim());
            *operation = detach_from<winrt::Windows::Foundation::IAsyncOperationWithProgress<winrt::Microsoft::Windows::Management::Deployment::PackageDeploymentResult, winrt::Microsoft::Windows::Management::Deployment::PackageDeploymentProgress>>(this->shim().MakeAvailableAsync());
            return 0;
        }
        catch (...) { return to_hresult(); }
        int32_t __stdcall CreateAsync(void** operation) noexcept final try
        {
            clear_abi(operation);
            typename D::abi_guard guard(this->shim());
            *operation = detach_from<winrt::Windows::Foundation::IAsyncOperation<winrt::Microsoft::Windows::AI::Generative::LanguageModel>>(this->shim().CreateAsync());
            return 0;
        }
        catch (...) { return to_hresult(); }
    };
#endif
}
WINRT_EXPORT namespace winrt::Microsoft::Windows::AI::Generative
{
    inline auto ImageDescriptionGenerator::IsAvailable()
    {
        return impl::call_factory_cast<bool(*)(IImageDescriptionGeneratorStatics const&), ImageDescriptionGenerator, IImageDescriptionGeneratorStatics>([](IImageDescriptionGeneratorStatics const& f) { return f.IsAvailable(); });
    }
    inline auto ImageDescriptionGenerator::MakeAvailableAsync()
    {
        return impl::call_factory_cast<winrt::Windows::Foundation::IAsyncOperationWithProgress<winrt::Microsoft::Windows::Management::Deployment::PackageDeploymentResult, winrt::Microsoft::Windows::Management::Deployment::PackageDeploymentProgress>(*)(IImageDescriptionGeneratorStatics const&), ImageDescriptionGenerator, IImageDescriptionGeneratorStatics>([](IImageDescriptionGeneratorStatics const& f) { return f.MakeAvailableAsync(); });
    }
    inline auto ImageDescriptionGenerator::CreateAsync()
    {
        return impl::call_factory_cast<winrt::Windows::Foundation::IAsyncOperation<winrt::Microsoft::Windows::AI::Generative::ImageDescriptionGenerator>(*)(IImageDescriptionGeneratorStatics const&), ImageDescriptionGenerator, IImageDescriptionGeneratorStatics>([](IImageDescriptionGeneratorStatics const& f) { return f.CreateAsync(); });
    }
    inline auto LanguageModel::IsAvailable()
    {
        return impl::call_factory_cast<bool(*)(ILanguageModelStatics const&), LanguageModel, ILanguageModelStatics>([](ILanguageModelStatics const& f) { return f.IsAvailable(); });
    }
    inline auto LanguageModel::MakeAvailableAsync()
    {
        return impl::call_factory_cast<winrt::Windows::Foundation::IAsyncOperationWithProgress<winrt::Microsoft::Windows::Management::Deployment::PackageDeploymentResult, winrt::Microsoft::Windows::Management::Deployment::PackageDeploymentProgress>(*)(ILanguageModelStatics const&), LanguageModel, ILanguageModelStatics>([](ILanguageModelStatics const& f) { return f.MakeAvailableAsync(); });
    }
    inline auto LanguageModel::CreateAsync()
    {
        return impl::call_factory_cast<winrt::Windows::Foundation::IAsyncOperation<winrt::Microsoft::Windows::AI::Generative::LanguageModel>(*)(ILanguageModelStatics const&), LanguageModel, ILanguageModelStatics>([](ILanguageModelStatics const& f) { return f.CreateAsync(); });
    }
    inline LanguageModelOptions::LanguageModelOptions() :
        LanguageModelOptions(impl::call_factory_cast<LanguageModelOptions(*)(winrt::Windows::Foundation::IActivationFactory const&), LanguageModelOptions>([](winrt::Windows::Foundation::IActivationFactory const& f) { return f.template ActivateInstance<LanguageModelOptions>(); }))
    {
    }
    inline LanguageModelOptions::LanguageModelOptions(winrt::Microsoft::Windows::AI::Generative::LanguageModelSkill const& skill, float temp, float top_p, uint32_t top_k) :
        LanguageModelOptions(impl::call_factory<LanguageModelOptions, ILanguageModelOptionsFactory>([&](ILanguageModelOptionsFactory const& f) { return f.CreateInstance(skill, temp, top_p, top_k); }))
    {
    }
    inline LanguageModelResponse::LanguageModelResponse(param::hstring const& response, winrt::Microsoft::Windows::AI::Generative::LanguageModelResponseStatus const& status) :
        LanguageModelResponse(impl::call_factory<LanguageModelResponse, ILanguageModelResponseFactory>([&](ILanguageModelResponseFactory const& f) { return f.CreateInstance(response, status); }))
    {
    }
}
namespace std
{
#ifndef WINRT_LEAN_AND_MEAN
    template<> struct hash<winrt::Microsoft::Windows::AI::Generative::IImageDescriptionGenerator> : winrt::impl::hash_base {};
    template<> struct hash<winrt::Microsoft::Windows::AI::Generative::IImageDescriptionGenerator2> : winrt::impl::hash_base {};
    template<> struct hash<winrt::Microsoft::Windows::AI::Generative::IImageDescriptionGenerator3> : winrt::impl::hash_base {};
    template<> struct hash<winrt::Microsoft::Windows::AI::Generative::IImageDescriptionGeneratorStatics> : winrt::impl::hash_base {};
    template<> struct hash<winrt::Microsoft::Windows::AI::Generative::ILanguageModel> : winrt::impl::hash_base {};
    template<> struct hash<winrt::Microsoft::Windows::AI::Generative::ILanguageModel2> : winrt::impl::hash_base {};
    template<> struct hash<winrt::Microsoft::Windows::AI::Generative::ILanguageModel3> : winrt::impl::hash_base {};
    template<> struct hash<winrt::Microsoft::Windows::AI::Generative::ILanguageModel4> : winrt::impl::hash_base {};
    template<> struct hash<winrt::Microsoft::Windows::AI::Generative::ILanguageModel5> : winrt::impl::hash_base {};
    template<> struct hash<winrt::Microsoft::Windows::AI::Generative::ILanguageModelContext> : winrt::impl::hash_base {};
    template<> struct hash<winrt::Microsoft::Windows::AI::Generative::ILanguageModelOptions> : winrt::impl::hash_base {};
    template<> struct hash<winrt::Microsoft::Windows::AI::Generative::ILanguageModelOptionsFactory> : winrt::impl::hash_base {};
    template<> struct hash<winrt::Microsoft::Windows::AI::Generative::ILanguageModelResponse> : winrt::impl::hash_base {};
    template<> struct hash<winrt::Microsoft::Windows::AI::Generative::ILanguageModelResponseFactory> : winrt::impl::hash_base {};
    template<> struct hash<winrt::Microsoft::Windows::AI::Generative::ILanguageModelStatics> : winrt::impl::hash_base {};
    template<> struct hash<winrt::Microsoft::Windows::AI::Generative::ImageDescriptionGenerator> : winrt::impl::hash_base {};
    template<> struct hash<winrt::Microsoft::Windows::AI::Generative::LanguageModel> : winrt::impl::hash_base {};
    template<> struct hash<winrt::Microsoft::Windows::AI::Generative::LanguageModelContext> : winrt::impl::hash_base {};
    template<> struct hash<winrt::Microsoft::Windows::AI::Generative::LanguageModelOptions> : winrt::impl::hash_base {};
    template<> struct hash<winrt::Microsoft::Windows::AI::Generative::LanguageModelResponse> : winrt::impl::hash_base {};
#endif
#ifdef __cpp_lib_format
#endif
}
#endif
